// use crate::treasury_forks::BankForks;
use crate::treasury_forks::BankForks;
use crate::block_buffer_pool::BlockBufferPool;
use crate::entry_info::{Entry, EntrySlice};
use crate::leader_arrange_cache::LeaderScheduleCache;
use rayon::prelude::*;
use morgan_metricbot::{datapoint, datapoint_error, inc_new_counter_debug};
use morgan_runtime::treasury::Bank;
use morgan_runtime::locked_accounts_results::LockedAccountsResults;
use morgan_interface::genesis_block::GenesisBlock;
use morgan_interface::timing::duration_as_ms;
use morgan_interface::timing::MAX_RECENT_BLOCKHASHES;
use morgan_interface::transaction::Result;
use morgan_interface::transaction::Transaction;
use std::result;
use std::sync::Arc;
use std::time::{Duration, Instant};
use morgan_helper::logHelper::*;

fn first_err(results: &[Result<()>]) -> Result<()> {
    for r in results {
        if r.is_err() {
            return r.clone();
        }
    }
    Ok(())
}

fn par_execute_entries(
    treasury: &Bank,
    entries: &[(&Entry, LockedAccountsResults<Transaction>)],
) -> Result<()> {
    inc_new_counter_debug!("treasury-par_execute_entries-count", entries.len());
    let results: Vec<Result<()>> = entries
        .into_par_iter()
        .map(|(e, locked_accounts)| {
            let results = treasury.load_execute_and_commit_transactions(
                &e.transactions,
                locked_accounts,
                MAX_RECENT_BLOCKHASHES,
            );
            let mut first_err = None;
            for (r, tx) in results.iter().zip(e.transactions.iter()) {
                if let Err(ref e) = r {
                    if first_err.is_none() {
                        first_err = Some(r.clone());
                    }
                    if !Bank::can_commit(&r) {
                        // warn!("Unexpected validator error: {:?}, tx: {:?}", e, tx);
                        println!(
                            "{}",
                            Warn(
                                format!("Unexpected validator error: {:?}, tx: {:?}", e, tx).to_string(),
                                module_path!().to_string()
                            )
                        );
                        datapoint_error!(
                            "validator_process_entry_error",
                            ("error", format!("error: {:?}, tx: {:?}", e, tx), String)
                        );
                    }
                }
            }
            first_err.unwrap_or(Ok(()))
        })
        .collect();

    first_err(&results)
}

/// Process an ordered list of entries in parallel
/// 1. In order lock accounts for each entry while the lock succeeds, up to a Tick entry
/// 2. Process the locked group in parallel
/// 3. Register the `Tick` if it's available
/// 4. Update the leader scheduler, goto 1
pub fn process_entries(treasury: &Bank, entries: &[Entry]) -> Result<()> {
    // accumulator for entries that can be processed in parallel
    let mut mt_group = vec![];
    for entry in entries {
        if entry.is_tick() {
            // if its a tick, execute the group and register the tick
            par_execute_entries(treasury, &mt_group)?;
            mt_group = vec![];
            treasury.register_tick(&entry.hash);
            continue;
        }
        // else loop on processing the entry
        loop {
            // try to lock the accounts
            let lock_results = treasury.lock_accounts(&entry.transactions);

            let first_lock_err = first_err(lock_results.locked_accounts_results());

            // if locking worked
            if first_lock_err.is_ok() {
                // push the entry to the mt_group
                mt_group.push((entry, lock_results));
                // done with this entry
                break;
            }
            // else we failed to lock, 2 possible reasons
            if mt_group.is_empty() {
                // An entry has account lock conflicts with *itself*, which should not happen
                // if generated by a properly functioning leader
                datapoint!(
                    "validator_process_entry_error",
                    (
                        "error",
                        format!(
                            "Lock accounts error, entry conflicts with itself, txs: {:?}",
                            entry.transactions
                        ),
                        String
                    )
                );
                // bail
                first_lock_err?;
            } else {
                // else we have an entry that conflicts with a prior entry
                // execute the current queue and try to process this entry again
                par_execute_entries(treasury, &mt_group)?;
                mt_group = vec![];
            }
        }
    }
    par_execute_entries(treasury, &mt_group)?;
    Ok(())
}

#[derive(Debug, PartialEq)]
pub struct BankForksInfo {
    pub bank_slot: u64,
    pub entry_height: u64,
}

#[derive(Debug)]
pub enum BlocktreeProcessorError {
    LedgerVerificationFailed,
}

pub fn process_block_buffer_pool(
    genesis_block: &GenesisBlock,
    block_buffer_pool: &BlockBufferPool,
    account_paths: Option<String>,
) -> result::Result<(BankForks, Vec<BankForksInfo>, LeaderScheduleCache), BlocktreeProcessorError> {
    let now = Instant::now();
    // info!("{}", Info(format!("processing ledger...").to_string()));
    let loginfo: String = format!("processing ledger...").to_string();
    println!("{}",
        printLn(
            loginfo,
            module_path!().to_string()
        )
    );
    // Setup treasury for slot 0
    let mut pending_slots = {
        let slot = 0;
        let treasury = Arc::new(Bank::new_with_paths(&genesis_block, account_paths));
        let entry_height = 0;
        let last_entry_hash = treasury.last_blockhash();

        // Load the metadata for this slot
        let meta = block_buffer_pool
            .meta(slot)
            .map_err(|err| {
                // warn!("Failed to load meta for slot {}: {:?}", slot, err);
                println!(
                    "{}",
                    Warn(
                        format!("Failed to load meta for slot {}: {:?}", slot, err).to_string(),
                        module_path!().to_string()
                    )
                );
                BlocktreeProcessorError::LedgerVerificationFailed
            })?
            .unwrap();

        vec![(slot, meta, treasury, entry_height, last_entry_hash)]
    };

    block_buffer_pool.set_genesis(0, 0).expect("Couldn't set first root");

    let leader_schedule_cache = LeaderScheduleCache::new(*pending_slots[0].2.epoch_schedule(), 0);

    let mut fork_info = vec![];
    let mut last_status_report = Instant::now();
    let mut root = 0;
    while !pending_slots.is_empty() {
        let (slot, meta, treasury, mut entry_height, mut last_entry_hash) =
            pending_slots.pop().unwrap();

        if last_status_report.elapsed() > Duration::from_secs(2) {
            // info!("{}", Info(format!("processing ledger...block {}", slot).to_string()));
            let loginfo: String = format!("processing ledger...block {}", slot).to_string();
            println!("{}",
                printLn(
                    loginfo,
                    module_path!().to_string()
                )
            );
            last_status_report = Instant::now();
        }

        // Fetch all entries for this slot
        let mut entries = block_buffer_pool.fetch_slot_entries(slot, 0, None).map_err(|err| {
            // warn!("Failed to load entries for slot {}: {:?}", slot, err);
            println!(
                "{}",
                Warn(
                    format!("Failed to load entries for slot {}: {:?}", slot, err).to_string(),
                    module_path!().to_string()
                )
            );
            BlocktreeProcessorError::LedgerVerificationFailed
        })?;

        if slot == 0 {
            // The first entry in the ledger is a pseudo-tick used only to ensure the number of ticks
            // in slot 0 is the same as the number of ticks in all subsequent slots.  It is not
            // processed by the treasury, skip over it.
            if entries.is_empty() {
                // warn!("entry0 not present");
                println!(
                    "{}",
                    Warn(
                        format!("entry0 not present").to_string(),
                        module_path!().to_string()
                    )
                );
                return Err(BlocktreeProcessorError::LedgerVerificationFailed);
            }
            let entry0 = entries.remove(0);
            if !(entry0.is_tick() && entry0.verify(&last_entry_hash)) {
                // warn!("Ledger proof of history failed at entry0");
                println!(
                    "{}",
                    Warn(
                        format!("Ledger proof of history failed at entry0").to_string(),
                        module_path!().to_string()
                    )
                );
                return Err(BlocktreeProcessorError::LedgerVerificationFailed);
            }
            last_entry_hash = entry0.hash;
            entry_height += 1;
        }

        if !entries.is_empty() {
            if !entries.verify(&last_entry_hash) {
                // warn!(
                //     "Ledger proof of history failed at slot: {}, entry: {}",
                //     slot, entry_height
                // );
                println!(
                    "{}",
                    Warn(
                        format!("Ledger proof of history failed at slot: {}, entry: {}",
                            slot, entry_height).to_string(),
                        module_path!().to_string()
                    )
                );
                return Err(BlocktreeProcessorError::LedgerVerificationFailed);
            }

            process_entries(&treasury, &entries).map_err(|err| {
                // warn!("Failed to process entries for slot {}: {:?}", slot, err);
                println!(
                    "{}",
                    Warn(
                        format!("Failed to process entries for slot {}: {:?}", slot, err).to_string(),
                        module_path!().to_string()
                    )
                );
                BlocktreeProcessorError::LedgerVerificationFailed
            })?;

            last_entry_hash = entries.last().unwrap().hash;
            entry_height += entries.len() as u64;
        }

        treasury.freeze(); // all banks handled by this routine are created from complete slots

        if block_buffer_pool.is_genesis(slot) {
            root = slot;
            leader_schedule_cache.set_genesis(slot);
            treasury.squash();
            pending_slots.clear();
            fork_info.clear();
        }

        if meta.next_slots.is_empty() {
            // Reached the end of this fork.  Record the final entry height and last entry.hash
            let bfi = BankForksInfo {
                bank_slot: slot,
                entry_height,
            };
            fork_info.push((treasury, bfi));
            continue;
        }

        // This is a fork point, create a new child treasury for each fork
        for next_slot in meta.next_slots {
            let next_meta = block_buffer_pool
                .meta(next_slot)
                .map_err(|err| {
                    // warn!("Failed to load meta for slot {}: {:?}", slot, err);
                    println!(
                        "{}",
                        Warn(
                            format!("Failed to load meta for slot {}: {:?}", slot, err).to_string(),
                            module_path!().to_string()
                        )
                    );
                    BlocktreeProcessorError::LedgerVerificationFailed
                })?
                .unwrap();

            // only process full slots in block_buffer_processor, replay_stage
            // handles any partials
            if next_meta.is_full() {
                let next_bank = Arc::new(Bank::new_from_parent(
                    &treasury,
                    &leader_schedule_cache
                        .slot_leader_at(next_slot, Some(&treasury))
                        .unwrap(),
                    next_slot,
                ));
                trace!("Add child treasury for slot={}", next_slot);
                // treasury_forks.insert(*next_slot, child_bank);
                pending_slots.push((
                    next_slot,
                    next_meta,
                    next_bank,
                    entry_height,
                    last_entry_hash,
                ));
            } else {
                let bfi = BankForksInfo {
                    bank_slot: slot,
                    entry_height,
                };
                fork_info.push((treasury.clone(), bfi));
            }
        }

        // reverse sort by slot, so the next slot to be processed can be pop()ed
        // TODO: remove me once leader_scheduler can hang with out-of-order slots?
        pending_slots.sort_by(|a, b| b.0.cmp(&a.0));
    }

    let (banks, treasury_forks_info): (Vec<_>, Vec<_>) = fork_info.into_iter().unzip();
    let treasury_forks = BankForks::new_from_banks(&banks, root);
    // info!(
    //     "{}",
    //     Info(format!("processing ledger...complete in {}ms, forks={}...",
    //     duration_as_ms(&now.elapsed()),
    //     treasury_forks_info.len()).to_string())
    // );
    let loginfo: String = format!("processing ledger...complete in {}ms, forks={}...",
        duration_as_ms(&now.elapsed()),
        treasury_forks_info.len()).to_string();
    println!("{}",
        printLn(
            loginfo,
            module_path!().to_string()
        )
    );
    // info!(
    //     "{}",
    //     Info(format!("---------------------------leader_schedule_cache--------------------------------").to_string())
    // );
    let loginfo: String = format!("~~~~~~~~~~~~~~~~~~~~~~~~~~~leader Arrange Cache~~~~~~~~~~~~~~~~~~~~~~~~~~~").to_string();
    println!("{}",
        printLn(
            loginfo,
            module_path!().to_string()
        )
    );
    // info!("{}", Info(format!("#############################################################################").to_string()));
    let loginfo: String = format!("#############################################################################").to_string();
    println!("{}",
        printLn(
            loginfo,
            module_path!().to_string()
        )
    );
    // info!("{}", Info(format!("#############################################################################").to_string()));
    let loginfo: String = format!("#############################################################################").to_string();
    println!("{}",
        printLn(
            loginfo,
            module_path!().to_string()
        )
    );
    // info!("{}", Info(format!("leader_schedule_cache.cached_schedules : {:?}", leader_schedule_cache.cached_schedules).to_string()));
    let loginfo: String = format!("leader Arrange Cache : {:?}", leader_schedule_cache.cached_schedules).to_string();
    println!("{}",
        printLn(
            loginfo,
            module_path!().to_string()
        )
    );
    Ok((treasury_forks, treasury_forks_info, leader_schedule_cache))
}

#[cfg(test)]
pub mod tests {
    use super::*;
    use crate::block_buffer_pool::create_new_tmp_ledger;
    use crate::block_buffer_pool::tests::entries_to_blobs;
    use crate::entry_info::{create_ticks, next_entry, next_entry_mut, Entry};
    use crate::genesis_utils::{
        create_genesis_block, create_genesis_block_with_leader, GenesisBlockInfo,
    };
    use morgan_runtime::epoch_schedule::EpochSchedule;
    use morgan_interface::hash::Hash;
    use morgan_interface::instruction::InstructionError;
    use morgan_interface::pubkey::Pubkey;
    use morgan_interface::signature::{Keypair, KeypairUtil};
    use morgan_interface::system_transaction;
    use morgan_interface::transaction::TransactionError;

    pub fn fill_block_buffer_pool_slot_with_ticks(
        block_buffer_pool: &BlockBufferPool,
        ticks_per_slot: u64,
        slot: u64,
        parent_slot: u64,
        last_entry_hash: Hash,
    ) -> Hash {
        let entries = create_ticks(ticks_per_slot, last_entry_hash);
        let last_entry_hash = entries.last().unwrap().hash;

        let blobs = entries_to_blobs(&entries, slot, parent_slot, true);
        block_buffer_pool.insert_data_blobs(blobs.iter()).unwrap();

        last_entry_hash
    }

    #[test]
    fn test_process_block_buffer_pool_with_incomplete_slot() {
        morgan_logger::setup();

        let GenesisBlockInfo { genesis_block, .. } = create_genesis_block(10_000);
        let ticks_per_slot = genesis_block.ticks_per_slot;

        /*
          Build a block_buffer_pool in the ledger with the following fork structure:

               slot 0 (all ticks)
                 |
               slot 1 (all ticks but one)
                 |
               slot 2 (all ticks)

           where slot 1 is incomplete (missing 1 tick at the end)
        */

        // Create a new ledger with slot 0 full of ticks
        let (ledger_path, mut blockhash) = create_new_tmp_ledger!(&genesis_block);
        debug!("ledger_path: {:?}", ledger_path);

        let block_buffer_pool =
            BlockBufferPool::open_ledger_file(&ledger_path).expect("Expected to successfully open database ledger");

        // Write slot 1
        // slot 1, points at slot 0.  Missing one tick
        {
            let parent_slot = 0;
            let slot = 1;
            let mut entries = create_ticks(ticks_per_slot, blockhash);
            blockhash = entries.last().unwrap().hash;

            // throw away last one
            entries.pop();

            let blobs = entries_to_blobs(&entries, slot, parent_slot, false);
            block_buffer_pool.insert_data_blobs(blobs.iter()).unwrap();
        }

        // slot 2, points at slot 1
        fill_block_buffer_pool_slot_with_ticks(&block_buffer_pool, ticks_per_slot, 2, 1, blockhash);

        let (mut _bank_forks, treasury_forks_info, _) =
            process_block_buffer_pool(&genesis_block, &block_buffer_pool, None).unwrap();

        assert_eq!(treasury_forks_info.len(), 1);
        assert_eq!(
            treasury_forks_info[0],
            BankForksInfo {
                bank_slot: 0, // slot 1 isn't "full", we stop at slot zero
                entry_height: ticks_per_slot,
            }
        );
    }

    #[test]
    fn test_process_block_buffer_with_two_forks_and_squash() {
        morgan_logger::setup();

        let GenesisBlockInfo { genesis_block, .. } = create_genesis_block(10_000);
        let ticks_per_slot = genesis_block.ticks_per_slot;

        // Create a new ledger with slot 0 full of ticks
        let (ledger_path, blockhash) = create_new_tmp_ledger!(&genesis_block);
        debug!("ledger_path: {:?}", ledger_path);
        let mut last_entry_hash = blockhash;

        /*
            Build a block_buffer_pool in the ledger with the following fork structure:

                 slot 0
                   |
                 slot 1
                 /   \
            slot 2   |
               /     |
            slot 3   |
                     |
                   slot 4 <-- set_genesis(true)

        */
        let block_buffer_pool =
            BlockBufferPool::open_ledger_file(&ledger_path).expect("Expected to successfully open database ledger");

        // Fork 1, ending at slot 3
        let last_slot1_entry_hash =
            fill_block_buffer_pool_slot_with_ticks(&block_buffer_pool, ticks_per_slot, 1, 0, last_entry_hash);
        last_entry_hash =
            fill_block_buffer_pool_slot_with_ticks(&block_buffer_pool, ticks_per_slot, 2, 1, last_slot1_entry_hash);
        let last_fork1_entry_hash =
            fill_block_buffer_pool_slot_with_ticks(&block_buffer_pool, ticks_per_slot, 3, 2, last_entry_hash);

        // Fork 2, ending at slot 4
        let last_fork2_entry_hash =
            fill_block_buffer_pool_slot_with_ticks(&block_buffer_pool, ticks_per_slot, 4, 1, last_slot1_entry_hash);

        // info!("{}", Info(format!("last_fork1_entry.hash: {:?}", last_fork1_entry_hash).to_string()));
        // info!("{}", Info(format!("last_fork2_entry.hash: {:?}", last_fork2_entry_hash).to_string()));
        let loginfo: String = format!("last_fork1_entry.hash: {:?}", last_fork1_entry_hash).to_string();
        println!("{}",
            printLn(
                loginfo,
                module_path!().to_string()
            )
        );
        let loginfo: String = format!("last_fork2_entry.hash: {:?}", last_fork2_entry_hash).to_string();
        println!("{}",
            printLn(
                loginfo,
                module_path!().to_string()
            )
        );
        block_buffer_pool.set_genesis(4, 0).unwrap();

        let (treasury_forks, treasury_forks_info, _) =
            process_block_buffer_pool(&genesis_block, &block_buffer_pool, None).unwrap();

        assert_eq!(treasury_forks_info.len(), 1); // One fork, other one is ignored b/c not a descendant of the root

        assert_eq!(
            treasury_forks_info[0],
            BankForksInfo {
                bank_slot: 4, // Fork 2's head is slot 4
                entry_height: ticks_per_slot * 3,
            }
        );
        assert!(&treasury_forks[4]
            .parents()
            .iter()
            .map(|treasury| treasury.slot())
            .collect::<Vec<_>>()
            .is_empty());

        // Ensure treasury_forks holds the right banks
        for info in treasury_forks_info {
            assert_eq!(treasury_forks[info.bank_slot].slot(), info.bank_slot);
            assert!(treasury_forks[info.bank_slot].is_frozen());
        }

        assert_eq!(treasury_forks.root(), 4);
    }

    #[test]
    fn test_process_block_buffer_with_two_forks() {
        morgan_logger::setup();

        let GenesisBlockInfo { genesis_block, .. } = create_genesis_block(10_000);
        let ticks_per_slot = genesis_block.ticks_per_slot;

        // Create a new ledger with slot 0 full of ticks
        let (ledger_path, blockhash) = create_new_tmp_ledger!(&genesis_block);
        debug!("ledger_path: {:?}", ledger_path);
        let mut last_entry_hash = blockhash;

        /*
            Build a block_buffer_pool in the ledger with the following fork structure:

                 slot 0
                   |
                 slot 1  <-- set_genesis(true)
                 /   \
            slot 2   |
               /     |
            slot 3   |
                     |
                   slot 4

        */
        let block_buffer_pool =
            BlockBufferPool::open_ledger_file(&ledger_path).expect("Expected to successfully open database ledger");

        // Fork 1, ending at slot 3
        let last_slot1_entry_hash =
            fill_block_buffer_pool_slot_with_ticks(&block_buffer_pool, ticks_per_slot, 1, 0, last_entry_hash);
        last_entry_hash =
            fill_block_buffer_pool_slot_with_ticks(&block_buffer_pool, ticks_per_slot, 2, 1, last_slot1_entry_hash);
        let last_fork1_entry_hash =
            fill_block_buffer_pool_slot_with_ticks(&block_buffer_pool, ticks_per_slot, 3, 2, last_entry_hash);

        // Fork 2, ending at slot 4
        let last_fork2_entry_hash =
            fill_block_buffer_pool_slot_with_ticks(&block_buffer_pool, ticks_per_slot, 4, 1, last_slot1_entry_hash);

        // info!("{}", Info(format!("last_fork1_entry.hash: {:?}", last_fork1_entry_hash).to_string()));
        // info!("{}", Info(format!("last_fork2_entry.hash: {:?}", last_fork2_entry_hash).to_string()));
        let loginfo: String = format!("last_fork1_entry.hash: {:?}", last_fork1_entry_hash).to_string();
        println!("{}",
            printLn(
                loginfo,
                module_path!().to_string()
            )
        );
        let loginfo: String = format!("last_fork2_entry.hash: {:?}", last_fork2_entry_hash).to_string();
        println!("{}",
            printLn(
                loginfo,
                module_path!().to_string()
            )
        );
        block_buffer_pool.set_genesis(0, 0).unwrap();
        block_buffer_pool.set_genesis(1, 0).unwrap();

        let (treasury_forks, treasury_forks_info, _) =
            process_block_buffer_pool(&genesis_block, &block_buffer_pool, None).unwrap();

        assert_eq!(treasury_forks_info.len(), 2); // There are two forks
        assert_eq!(
            treasury_forks_info[0],
            BankForksInfo {
                bank_slot: 3, // Fork 1's head is slot 3
                entry_height: ticks_per_slot * 4,
            }
        );
        assert_eq!(
            &treasury_forks[3]
                .parents()
                .iter()
                .map(|treasury| treasury.slot())
                .collect::<Vec<_>>(),
            &[2, 1]
        );
        assert_eq!(
            treasury_forks_info[1],
            BankForksInfo {
                bank_slot: 4, // Fork 2's head is slot 4
                entry_height: ticks_per_slot * 3,
            }
        );
        assert_eq!(
            &treasury_forks[4]
                .parents()
                .iter()
                .map(|treasury| treasury.slot())
                .collect::<Vec<_>>(),
            &[1]
        );

        assert_eq!(treasury_forks.root(), 1);

        // Ensure treasury_forks holds the right banks
        for info in treasury_forks_info {
            assert_eq!(treasury_forks[info.bank_slot].slot(), info.bank_slot);
            assert!(treasury_forks[info.bank_slot].is_frozen());
        }
    }

    #[test]
    fn test_process_block_buffer_epoch_boundary_root() {
        morgan_logger::setup();

        let GenesisBlockInfo { genesis_block, .. } = create_genesis_block(10_000);
        let ticks_per_slot = genesis_block.ticks_per_slot;

        // Create a new ledger with slot 0 full of ticks
        let (ledger_path, blockhash) = create_new_tmp_ledger!(&genesis_block);
        let mut last_entry_hash = blockhash;

        let block_buffer_pool =
            BlockBufferPool::open_ledger_file(&ledger_path).expect("Expected to successfully open database ledger");

        // Let last_slot be the number of slots in the first two epochs
        let epoch_schedule = get_epoch_schedule(&genesis_block, None);
        let last_slot = epoch_schedule.get_last_slot_in_epoch(1);

        // Create a single chain of slots with all indexes in the range [0, last_slot + 1]
        for i in 1..=last_slot + 1 {
            last_entry_hash = fill_block_buffer_pool_slot_with_ticks(
                &block_buffer_pool,
                ticks_per_slot,
                i,
                i - 1,
                last_entry_hash,
            );
        }

        // Set a root on the last slot of the last confirmed epoch
        block_buffer_pool.set_genesis(last_slot, 0).unwrap();

        // Set a root on the next slot of the confrimed epoch
        block_buffer_pool.set_genesis(last_slot + 1, last_slot).unwrap();

        // Check that we can properly restart the ledger / leader scheduler doesn't fail
        let (treasury_forks, treasury_forks_info, _) =
            process_block_buffer_pool(&genesis_block, &block_buffer_pool, None).unwrap();

        assert_eq!(treasury_forks_info.len(), 1); // There is one fork
        assert_eq!(
            treasury_forks_info[0],
            BankForksInfo {
                bank_slot: last_slot + 1, // Head is last_slot + 1
                entry_height: ticks_per_slot * (last_slot + 2),
            }
        );

        // The latest root should have purged all its parents
        assert!(&treasury_forks[last_slot + 1]
            .parents()
            .iter()
            .map(|treasury| treasury.slot())
            .collect::<Vec<_>>()
            .is_empty());
    }

    #[test]
    fn test_first_err() {
        assert_eq!(first_err(&[Ok(())]), Ok(()));
        assert_eq!(
            first_err(&[Ok(()), Err(TransactionError::DuplicateSignature)]),
            Err(TransactionError::DuplicateSignature)
        );
        assert_eq!(
            first_err(&[
                Ok(()),
                Err(TransactionError::DuplicateSignature),
                Err(TransactionError::AccountInUse)
            ]),
            Err(TransactionError::DuplicateSignature)
        );
        assert_eq!(
            first_err(&[
                Ok(()),
                Err(TransactionError::AccountInUse),
                Err(TransactionError::DuplicateSignature)
            ]),
            Err(TransactionError::AccountInUse)
        );
        assert_eq!(
            first_err(&[
                Err(TransactionError::AccountInUse),
                Ok(()),
                Err(TransactionError::DuplicateSignature)
            ]),
            Err(TransactionError::AccountInUse)
        );
    }

    #[test]
    fn test_process_empty_entry_is_registered() {
        morgan_logger::setup();

        let GenesisBlockInfo {
            genesis_block,
            mint_keypair,
            ..
        } = create_genesis_block(2);
        let treasury = Bank::new(&genesis_block);
        let keypair = Keypair::new();
        let slot_entries = create_ticks(genesis_block.ticks_per_slot - 1, genesis_block.hash());
        let tx = system_transaction::create_user_account(
            &mint_keypair,
            &keypair.pubkey(),
            1,
            slot_entries.last().unwrap().hash,
        );

        // First, ensure the TX is rejected because of the unregistered last ID
        assert_eq!(
            treasury.process_transaction(&tx),
            Err(TransactionError::BlockhashNotFound)
        );

        // Now ensure the TX is accepted despite pointing to the ID of an empty entry.
        process_entries(&treasury, &slot_entries).unwrap();
        assert_eq!(treasury.process_transaction(&tx), Ok(()));
    }

    #[test]
    fn test_process_ledger_simple() {
        morgan_logger::setup();
        let leader_pubkey = Pubkey::new_rand();
        let mint = 100;
        let GenesisBlockInfo {
            genesis_block,
            mint_keypair,
            ..
        } = create_genesis_block_with_leader(mint, &leader_pubkey, 50);
        let (ledger_path, mut last_entry_hash) = create_new_tmp_ledger!(&genesis_block);
        debug!("ledger_path: {:?}", ledger_path);

        let deducted_from_mint = 3;
        let mut entries = vec![];
        let blockhash = genesis_block.hash();
        for _ in 0..deducted_from_mint {
            // Transfer one token from the mint to a random account
            let keypair = Keypair::new();
            let tx = system_transaction::create_user_account(
                &mint_keypair,
                &keypair.pubkey(),
                1,
                blockhash,
            );
            let entry = Entry::new(&last_entry_hash, 1, vec![tx]);
            last_entry_hash = entry.hash;
            entries.push(entry);

            // Add a second Transaction that will produce a
            // InstructionError<0, ResultWithNegativeDifs> error when processed
            let keypair2 = Keypair::new();
            let tx = system_transaction::create_user_account(
                &keypair,
                &keypair2.pubkey(),
                42,
                blockhash,
            );
            let entry = Entry::new(&last_entry_hash, 1, vec![tx]);
            last_entry_hash = entry.hash;
            entries.push(entry);
        }

        // Fill up the rest of slot 1 with ticks
        entries.extend(create_ticks(genesis_block.ticks_per_slot, last_entry_hash));

        let block_buffer_pool =
            BlockBufferPool::open_ledger_file(&ledger_path).expect("Expected to successfully open database ledger");
        block_buffer_pool
            .update_entries(1, 0, 0, genesis_block.ticks_per_slot, &entries)
            .unwrap();
        let entry_height = genesis_block.ticks_per_slot + entries.len() as u64;
        let (treasury_forks, treasury_forks_info, _) =
            process_block_buffer_pool(&genesis_block, &block_buffer_pool, None).unwrap();

        assert_eq!(treasury_forks_info.len(), 1);
        assert_eq!(treasury_forks.root(), 0);
        assert_eq!(
            treasury_forks_info[0],
            BankForksInfo {
                bank_slot: 1,
                entry_height,
            }
        );

        let treasury = treasury_forks[1].clone();
        assert_eq!(
            treasury.get_balance(&mint_keypair.pubkey()),
            mint - deducted_from_mint
        );
        assert_eq!(treasury.tick_height(), 2 * genesis_block.ticks_per_slot - 1);
        assert_eq!(treasury.last_blockhash(), entries.last().unwrap().hash);
    }

    #[test]
    fn test_process_ledger_with_one_tick_per_slot() {
        let GenesisBlockInfo {
            mut genesis_block, ..
        } = create_genesis_block(123);
        genesis_block.ticks_per_slot = 1;
        let (ledger_path, _blockhash) = create_new_tmp_ledger!(&genesis_block);

        let block_buffer_pool = BlockBufferPool::open_ledger_file(&ledger_path).unwrap();
        let (treasury_forks, treasury_forks_info, _) =
            process_block_buffer_pool(&genesis_block, &block_buffer_pool, None).unwrap();

        assert_eq!(treasury_forks_info.len(), 1);
        assert_eq!(
            treasury_forks_info[0],
            BankForksInfo {
                bank_slot: 0,
                entry_height: 1,
            }
        );
        let treasury = treasury_forks[0].clone();
        assert_eq!(treasury.tick_height(), 0);
    }

    #[test]
    fn test_process_entries_tick() {
        let GenesisBlockInfo { genesis_block, .. } = create_genesis_block(1000);
        let treasury = Bank::new(&genesis_block);

        // ensure treasury can process a tick
        assert_eq!(treasury.tick_height(), 0);
        let tick = next_entry(&genesis_block.hash(), 1, vec![]);
        assert_eq!(process_entries(&treasury, &[tick.clone()]), Ok(()));
        assert_eq!(treasury.tick_height(), 1);
    }

    #[test]
    fn test_process_entries_2_entries_collision() {
        let GenesisBlockInfo {
            genesis_block,
            mint_keypair,
            ..
        } = create_genesis_block(1000);
        let treasury = Bank::new(&genesis_block);
        let keypair1 = Keypair::new();
        let keypair2 = Keypair::new();

        let blockhash = treasury.last_blockhash();

        // ensure treasury can process 2 entries that have a common account and no tick is registered
        let tx = system_transaction::create_user_account(
            &mint_keypair,
            &keypair1.pubkey(),
            2,
            treasury.last_blockhash(),
        );
        let entry_1 = next_entry(&blockhash, 1, vec![tx]);
        let tx = system_transaction::create_user_account(
            &mint_keypair,
            &keypair2.pubkey(),
            2,
            treasury.last_blockhash(),
        );
        let entry_2 = next_entry(&entry_1.hash, 1, vec![tx]);
        assert_eq!(process_entries(&treasury, &[entry_1, entry_2]), Ok(()));
        assert_eq!(treasury.get_balance(&keypair1.pubkey()), 2);
        assert_eq!(treasury.get_balance(&keypair2.pubkey()), 2);
        assert_eq!(treasury.last_blockhash(), blockhash);
    }

    #[test]
    fn test_process_entries_2_txes_collision() {
        let GenesisBlockInfo {
            genesis_block,
            mint_keypair,
            ..
        } = create_genesis_block(1000);
        let treasury = Bank::new(&genesis_block);
        let keypair1 = Keypair::new();
        let keypair2 = Keypair::new();
        let keypair3 = Keypair::new();

        // fund: put 4 in each of 1 and 2
        assert_matches!(treasury.transfer(4, &mint_keypair, &keypair1.pubkey()), Ok(_));
        assert_matches!(treasury.transfer(4, &mint_keypair, &keypair2.pubkey()), Ok(_));

        // construct an Entry whose 2nd transaction would cause a lock conflict with previous entry
        let entry_1_to_mint = next_entry(
            &treasury.last_blockhash(),
            1,
            vec![system_transaction::create_user_account(
                &keypair1,
                &mint_keypair.pubkey(),
                1,
                treasury.last_blockhash(),
            )],
        );

        let entry_2_to_3_mint_to_1 = next_entry(
            &entry_1_to_mint.hash,
            1,
            vec![
                system_transaction::create_user_account(
                    &keypair2,
                    &keypair3.pubkey(),
                    2,
                    treasury.last_blockhash(),
                ), // should be fine
                system_transaction::create_user_account(
                    &keypair1,
                    &mint_keypair.pubkey(),
                    2,
                    treasury.last_blockhash(),
                ), // will collide
            ],
        );

        assert_eq!(
            process_entries(&treasury, &[entry_1_to_mint, entry_2_to_3_mint_to_1]),
            Ok(())
        );

        assert_eq!(treasury.get_balance(&keypair1.pubkey()), 1);
        assert_eq!(treasury.get_balance(&keypair2.pubkey()), 2);
        assert_eq!(treasury.get_balance(&keypair3.pubkey()), 2);
    }

    #[test]
    fn test_process_entries_2_txes_collision_and_error() {
        let GenesisBlockInfo {
            genesis_block,
            mint_keypair,
            ..
        } = create_genesis_block(1000);
        let treasury = Bank::new(&genesis_block);
        let keypair1 = Keypair::new();
        let keypair2 = Keypair::new();
        let keypair3 = Keypair::new();
        let keypair4 = Keypair::new();

        // fund: put 4 in each of 1 and 2
        assert_matches!(treasury.transfer(4, &mint_keypair, &keypair1.pubkey()), Ok(_));
        assert_matches!(treasury.transfer(4, &mint_keypair, &keypair2.pubkey()), Ok(_));
        assert_matches!(treasury.transfer(4, &mint_keypair, &keypair4.pubkey()), Ok(_));

        // construct an Entry whose 2nd transaction would cause a lock conflict with previous entry
        let entry_1_to_mint = next_entry(
            &treasury.last_blockhash(),
            1,
            vec![
                system_transaction::create_user_account(
                    &keypair1,
                    &mint_keypair.pubkey(),
                    1,
                    treasury.last_blockhash(),
                ),
                system_transaction::transfer(
                    &keypair4,
                    &keypair4.pubkey(),
                    1,
                    Hash::default(), // Should cause a transaction failure with BlockhashNotFound
                ),
            ],
        );

        let entry_2_to_3_mint_to_1 = next_entry(
            &entry_1_to_mint.hash,
            1,
            vec![
                system_transaction::create_user_account(
                    &keypair2,
                    &keypair3.pubkey(),
                    2,
                    treasury.last_blockhash(),
                ), // should be fine
                system_transaction::create_user_account(
                    &keypair1,
                    &mint_keypair.pubkey(),
                    2,
                    treasury.last_blockhash(),
                ), // will collide
            ],
        );

        assert!(process_entries(
            &treasury,
            &[entry_1_to_mint.clone(), entry_2_to_3_mint_to_1.clone()]
        )
        .is_err());

        // First transaction in first entry succeeded, so keypair1 lost 1 dif
        assert_eq!(treasury.get_balance(&keypair1.pubkey()), 3);
        assert_eq!(treasury.get_balance(&keypair2.pubkey()), 4);

        // Check all accounts are unlocked
        let txs1 = &entry_1_to_mint.transactions[..];
        let txs2 = &entry_2_to_3_mint_to_1.transactions[..];
        let locked_accounts1 = treasury.lock_accounts(txs1);
        for result in locked_accounts1.locked_accounts_results() {
            assert!(result.is_ok());
        }
        // txs1 and txs2 have accounts that conflict, so we must drop txs1 first
        drop(locked_accounts1);
        let locked_accounts2 = treasury.lock_accounts(txs2);
        for result in locked_accounts2.locked_accounts_results() {
            assert!(result.is_ok());
        }
    }

    #[test]
    fn test_process_entries_2nd_entry_collision_with_self_and_error() {
        morgan_logger::setup();

        let GenesisBlockInfo {
            genesis_block,
            mint_keypair,
            ..
        } = create_genesis_block(1000);
        let treasury = Bank::new(&genesis_block);
        let keypair1 = Keypair::new();
        let keypair2 = Keypair::new();
        let keypair3 = Keypair::new();

        // fund: put some money in each of 1 and 2
        assert_matches!(treasury.transfer(5, &mint_keypair, &keypair1.pubkey()), Ok(_));
        assert_matches!(treasury.transfer(4, &mint_keypair, &keypair2.pubkey()), Ok(_));

        // 3 entries: first has a transfer, 2nd has a conflict with 1st, 3rd has a conflict with itself
        let entry_1_to_mint = next_entry(
            &treasury.last_blockhash(),
            1,
            vec![system_transaction::transfer(
                &keypair1,
                &mint_keypair.pubkey(),
                1,
                treasury.last_blockhash(),
            )],
        );
        // should now be:
        // keypair1=4
        // keypair2=4
        // keypair3=0

        let entry_2_to_3_and_1_to_mint = next_entry(
            &entry_1_to_mint.hash,
            1,
            vec![
                system_transaction::create_user_account(
                    &keypair2,
                    &keypair3.pubkey(),
                    2,
                    treasury.last_blockhash(),
                ), // should be fine
                system_transaction::transfer(
                    &keypair1,
                    &mint_keypair.pubkey(),
                    2,
                    treasury.last_blockhash(),
                ), // will collide with predecessor
            ],
        );
        // should now be:
        // keypair1=2
        // keypair2=2
        // keypair3=2

        let entry_conflict_itself = next_entry(
            &entry_2_to_3_and_1_to_mint.hash,
            1,
            vec![
                system_transaction::transfer(
                    &keypair1,
                    &keypair3.pubkey(),
                    1,
                    treasury.last_blockhash(),
                ),
                system_transaction::transfer(
                    &keypair1,
                    &keypair2.pubkey(),
                    1,
                    treasury.last_blockhash(),
                ), // should be fine
            ],
        );
        // would now be:
        // keypair1=0
        // keypair2=3
        // keypair3=3

        assert!(process_entries(
            &treasury,
            &[
                entry_1_to_mint.clone(),
                entry_2_to_3_and_1_to_mint.clone(),
                entry_conflict_itself.clone()
            ]
        )
        .is_err());

        // last entry should have been aborted before par_execute_entries
        assert_eq!(treasury.get_balance(&keypair1.pubkey()), 2);
        assert_eq!(treasury.get_balance(&keypair2.pubkey()), 2);
        assert_eq!(treasury.get_balance(&keypair3.pubkey()), 2);
    }

    #[test]
    fn test_process_entries_2_entries_par() {
        let GenesisBlockInfo {
            genesis_block,
            mint_keypair,
            ..
        } = create_genesis_block(1000);
        let treasury = Bank::new(&genesis_block);
        let keypair1 = Keypair::new();
        let keypair2 = Keypair::new();
        let keypair3 = Keypair::new();
        let keypair4 = Keypair::new();

        //load accounts
        let tx = system_transaction::create_user_account(
            &mint_keypair,
            &keypair1.pubkey(),
            1,
            treasury.last_blockhash(),
        );
        assert_eq!(treasury.process_transaction(&tx), Ok(()));
        let tx = system_transaction::create_user_account(
            &mint_keypair,
            &keypair2.pubkey(),
            1,
            treasury.last_blockhash(),
        );
        assert_eq!(treasury.process_transaction(&tx), Ok(()));

        // ensure treasury can process 2 entries that do not have a common account and no tick is registered
        let blockhash = treasury.last_blockhash();
        let tx = system_transaction::create_user_account(
            &keypair1,
            &keypair3.pubkey(),
            1,
            treasury.last_blockhash(),
        );
        let entry_1 = next_entry(&blockhash, 1, vec![tx]);
        let tx = system_transaction::create_user_account(
            &keypair2,
            &keypair4.pubkey(),
            1,
            treasury.last_blockhash(),
        );
        let entry_2 = next_entry(&entry_1.hash, 1, vec![tx]);
        assert_eq!(process_entries(&treasury, &[entry_1, entry_2]), Ok(()));
        assert_eq!(treasury.get_balance(&keypair3.pubkey()), 1);
        assert_eq!(treasury.get_balance(&keypair4.pubkey()), 1);
        assert_eq!(treasury.last_blockhash(), blockhash);
    }

    #[test]
    fn test_process_entries_2_entries_tick() {
        let GenesisBlockInfo {
            genesis_block,
            mint_keypair,
            ..
        } = create_genesis_block(1000);
        let treasury = Bank::new(&genesis_block);
        let keypair1 = Keypair::new();
        let keypair2 = Keypair::new();
        let keypair3 = Keypair::new();
        let keypair4 = Keypair::new();

        //load accounts
        let tx = system_transaction::create_user_account(
            &mint_keypair,
            &keypair1.pubkey(),
            1,
            treasury.last_blockhash(),
        );
        assert_eq!(treasury.process_transaction(&tx), Ok(()));
        let tx = system_transaction::create_user_account(
            &mint_keypair,
            &keypair2.pubkey(),
            1,
            treasury.last_blockhash(),
        );
        assert_eq!(treasury.process_transaction(&tx), Ok(()));

        let blockhash = treasury.last_blockhash();
        while blockhash == treasury.last_blockhash() {
            treasury.register_tick(&Hash::default());
        }

        // ensure treasury can process 2 entries that do not have a common account and tick is registered
        let tx =
            system_transaction::create_user_account(&keypair2, &keypair3.pubkey(), 1, blockhash);
        let entry_1 = next_entry(&blockhash, 1, vec![tx]);
        let tick = next_entry(&entry_1.hash, 1, vec![]);
        let tx = system_transaction::create_user_account(
            &keypair1,
            &keypair4.pubkey(),
            1,
            treasury.last_blockhash(),
        );
        let entry_2 = next_entry(&tick.hash, 1, vec![tx]);
        assert_eq!(
            process_entries(&treasury, &[entry_1.clone(), tick.clone(), entry_2.clone()]),
            Ok(())
        );
        assert_eq!(treasury.get_balance(&keypair3.pubkey()), 1);
        assert_eq!(treasury.get_balance(&keypair4.pubkey()), 1);

        // ensure that an error is returned for an empty account (keypair2)
        let tx = system_transaction::create_user_account(
            &keypair2,
            &keypair3.pubkey(),
            1,
            treasury.last_blockhash(),
        );
        let entry_3 = next_entry(&entry_2.hash, 1, vec![tx]);
        assert_eq!(
            process_entries(&treasury, &[entry_3]),
            Err(TransactionError::AccountNotFound)
        );
    }

    #[test]
    fn test_update_transaction_statuses() {
        // Make sure instruction errors still update the signature cache
        let GenesisBlockInfo {
            genesis_block,
            mint_keypair,
            ..
        } = create_genesis_block(11_000);
        let treasury = Bank::new(&genesis_block);
        let pubkey = Pubkey::new_rand();
        treasury.transfer(1_000, &mint_keypair, &pubkey).unwrap();
        assert_eq!(treasury.transaction_count(), 1);
        assert_eq!(treasury.get_balance(&pubkey), 1_000);
        assert_eq!(
            treasury.transfer(10_001, &mint_keypair, &pubkey),
            Err(TransactionError::InstructionError(
                0,
                InstructionError::new_result_with_negative_difs(),
            ))
        );
        assert_eq!(
            treasury.transfer(10_001, &mint_keypair, &pubkey),
            Err(TransactionError::DuplicateSignature)
        );

        // Make sure other errors don't update the signature cache
        let tx =
            system_transaction::create_user_account(&mint_keypair, &pubkey, 1000, Hash::default());
        let signature = tx.signatures[0];

        // Should fail with blockhash not found
        assert_eq!(
            treasury.process_transaction(&tx).map(|_| signature),
            Err(TransactionError::BlockhashNotFound)
        );

        // Should fail again with blockhash not found
        assert_eq!(
            treasury.process_transaction(&tx).map(|_| signature),
            Err(TransactionError::BlockhashNotFound)
        );
    }

    #[test]
    fn test_update_transaction_statuses_fail() {
        let GenesisBlockInfo {
            genesis_block,
            mint_keypair,
            ..
        } = create_genesis_block(11_000);
        let treasury = Bank::new(&genesis_block);
        let keypair1 = Keypair::new();
        let keypair2 = Keypair::new();
        let success_tx = system_transaction::create_user_account(
            &mint_keypair,
            &keypair1.pubkey(),
            1,
            treasury.last_blockhash(),
        );
        let fail_tx = system_transaction::create_user_account(
            &mint_keypair,
            &keypair2.pubkey(),
            2,
            treasury.last_blockhash(),
        );

        let entry_1_to_mint = next_entry(
            &treasury.last_blockhash(),
            1,
            vec![
                success_tx,
                fail_tx.clone(), // will collide
            ],
        );

        assert_eq!(
            process_entries(&treasury, &[entry_1_to_mint]),
            Err(TransactionError::AccountInUse)
        );

        // Should not see duplicate signature error
        assert_eq!(treasury.process_transaction(&fail_tx), Ok(()));
    }

    #[test]
    #[ignore]
    fn test_process_entries_stress() {
        // this test throws lots of rayon threads at process_entries()
        //  finds bugs in very low-layer stuff
        morgan_logger::setup();
        let GenesisBlockInfo {
            genesis_block,
            mint_keypair,
            ..
        } = create_genesis_block(1_000_000_000);
        let mut treasury = Bank::new(&genesis_block);

        const NUM_TRANSFERS: usize = 100;
        let keypairs: Vec<_> = (0..NUM_TRANSFERS * 2).map(|_| Keypair::new()).collect();

        // give everybody one dif
        for keypair in &keypairs {
            treasury.transfer(1, &mint_keypair, &keypair.pubkey())
                .expect("funding failed");
        }

        let mut i = 0;
        let mut hash = treasury.last_blockhash();
        loop {
            let entries: Vec<_> = (0..NUM_TRANSFERS)
                .map(|i| {
                    next_entry_mut(
                        &mut hash,
                        0,
                        vec![system_transaction::transfer(
                            &keypairs[i],
                            &keypairs[i + NUM_TRANSFERS].pubkey(),
                            1,
                            treasury.last_blockhash(),
                        )],
                    )
                })
                .collect();
            // info!("paying iteration {}", i);
            let loginfo: String = format!("paying iteration {}", i).to_string();
            println!("{}",
                printLn(
                    loginfo,
                    module_path!().to_string()
                )
            );
            process_entries(&treasury, &entries).expect("paying failed");

            let entries: Vec<_> = (0..NUM_TRANSFERS)
                .map(|i| {
                    next_entry_mut(
                        &mut hash,
                        0,
                        vec![system_transaction::transfer(
                            &keypairs[i + NUM_TRANSFERS],
                            &keypairs[i].pubkey(),
                            1,
                            treasury.last_blockhash(),
                        )],
                    )
                })
                .collect();

            // info!("{}", Info(format!("refunding iteration {}", i).to_string()));
            let loginfo: String = format!("refunding iteration {}", i).to_string();
            println!("{}",
                printLn(
                    loginfo,
                    module_path!().to_string()
                )
            );
            process_entries(&treasury, &entries).expect("refunding failed");

            // advance to next block
            process_entries(
                &treasury,
                &(0..treasury.ticks_per_slot())
                    .map(|_| next_entry_mut(&mut hash, 1, vec![]))
                    .collect::<Vec<_>>(),
            )
            .expect("process ticks failed");

            i += 1;
            treasury = Bank::new_from_parent(&Arc::new(treasury), &Pubkey::default(), i as u64);
            treasury.squash();
        }
    }

    fn get_epoch_schedule(
        genesis_block: &GenesisBlock,
        account_paths: Option<String>,
    ) -> EpochSchedule {
        let treasury = Bank::new_with_paths(&genesis_block, account_paths);
        treasury.epoch_schedule().clone()
    }
}
